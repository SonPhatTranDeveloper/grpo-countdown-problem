# Default training configuration for GRPO

# Learning parameters
learning_rate: 5e-7
warmup_ratio: 0.01
lr_scheduler_type: cosine
optim: adamw_8bit
beta: 0.001

# Training parameters
num_train_epochs: 1
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
bf16: true
remove_unused_columns: false

# Generation parameters
temperature: 1.0
max_completion_length: 1024
num_generations: 8
max_prompt_length: 4096

# Logging and saving
report_to: tensorboard
logging_steps: 1
save_strategy: steps
save_steps: 50
